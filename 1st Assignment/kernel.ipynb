{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA\nfrom matplotlib.pyplot import (figure, title, boxplot, xticks, subplot, hist,\n                               xlabel, ylim, yticks, show)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\ndata = pd.read_csv(\"../input/\" + os.listdir(\"../input\")[0])\n\n# attributeNames = [name[0][0] for name in mat_data['attributeNames']]\n# classNames = [cls[0][0] for cls in mat_data['classNames']]\n\n# X = mat_data['X']\n# y = mat_data['y'].squeeze()\n# C = mat_data['C'][0,0]\n# M = mat_data['M'][0,0]\n\n# print(data)\n\nfig,axes =plt.subplots(1,1, figsize=(14, 10))\n# figure()\n# title('Wine: Boxplot')\nnew_data = data[['age','trestbps','chol','fbs','thalach','oldpeak','ca','thal']]\naxes.get_yaxis().set_visible(False)\nnew_data.boxplot(grid=False)\n# xticks(range(1,M+1), attributeNames, rotation=45)\nshow()\n\n\n\n# pca=PCA().fit(X_train)\n# print(pca.explained_variance_ratio_)\n# print()\n# print(X_train.columns.values.tolist())\n# print(pca.components_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "542875f98cda5682ac2525fb118af5c26242e2a4"
      },
      "cell_type": "code",
      "source": "# from scipy import stats\n# pts = 1000\n# np.random.seed(28041990)\n# a = np.random.normal(0, 1, size=pts)\n# b = np.random.normal(2, 1, size=pts)\n# x = np.concatenate((a, b))\n# k2, p = stats.normaltest(x)\n# data.normaltest()\n# alpha = 1e-3\n# print(\"p = {:g}\".format(p))\n# if p < alpha:  # null hypothesis: x comes from a normal distribution\n# ...     print(\"The null hypothesis can be rejected\")\n# ... else:\n# ...     print(\"The null hypothesis cannot be rejected\")\n# The null hypothesis can be rejected\n\n# import numpy as np\nfrom scipy.stats import norm\n# import matplotlib.pyplot as plt\n\nfig,axes =plt.subplots(14,1, figsize=(12, 9))\nfor v, i in enumerate(data):\n    \n    # Fit a normal distribution to the data:\n    mu, std = norm.fit(data[i])\n\n    # Plot the histogram.\n#     plt.subplot(1)\n#     print(axes[0,1])\n    plt.hist(data[i], bins=25, density=True, alpha=0.6, color='b', ax=axes[v])\n    # Plot the PDF.\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, std)\n    plt.plot(x, p, 'k', linewidth=2)\n    title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n    plt.title(title)\n#     plt.subplot()\n\n# plt.tight_layout()\n# plt.show()\n\n# g = data.groupby('Name').Zscore\n# n = data.groups\n# fig, axes = plt.subplots(14 // 2, 2, figsize=(6, 6), sharex=True, sharey=True)\n# for i, (name, group) in enumerate(data):\n#     r, c = i // 2, i % 2\n#     a1 = axes[r, c]\n#     a2 = a1.twinx()\n#     group.plot.hist(ax=a2, alpha=.3)\n#     group.plot.kde(title=name, ax=a1, c='r')\n# fig,axes =plt.subplots(figsize=(14, 10))\n# data.hist(density=True,figsize=(14,10), grid=False,)\n# for column in data:\n#     r, c = i // 2, i % 2\n#     a1 = axes[r, c]\n#     a2 = a1.twinx()\n#     group.plot.hist(ax=a2, alpha=.3)\n#     group.plot.kde(title=name, ax=a1, c='r')\nplt.tight_layout()\nshow()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "711ec5910dac041d905a5b0d89ef786bd6982da3"
      },
      "cell_type": "code",
      "source": "\ndata.corr()\n\n\n\nX=data.drop(['target'],axis=1)\nX.corrwith(data['target']).plot.bar(\n        figsize = (12, 8), fontsize = 20,\n        rot = 90, grid = False)\nplt.gca().yaxis.grid(True)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d33e02dcc5241df373a76669afb17713ed5367f"
      },
      "cell_type": "code",
      "source": "dataX=X\ndataY=data['target']\nfrom sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\n\nX_train,X_test,y_train,y_test=train_test_split(dataX,dataY,test_size=0.2,random_state=42)\n\n# Normalize\n# X_train=(X_train-np.min(X_train))/(np.max(X_train)-np.min(X_train)).values\n# X_test=(X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test)).values\n\nX = (dataX-np.min(dataX)/(np.max(dataX)-np.min(dataX))).values\n\n\n\nfrom sklearn.decomposition import PCA\npca=PCA().fit(X)\nprint(pca.explained_variance_ratio_)\nprint()\nprint(X_train.columns.values.tolist())\nprint(pca.components_)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1150afa324ba230a8c740764b2a7a108a1b70da"
      },
      "cell_type": "code",
      "source": "\n\ncumulative=np.cumsum(pca.explained_variance_ratio_)\nplt.figure(figsize=(12, 8))\nplt.step([i for i in range(len(cumulative))],cumulative)\nplt.show()\n\n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "504b45b0be3906ec95327cf9e548d0874eabdf18"
      },
      "cell_type": "code",
      "source": "# pca = PCA(n_components=2)\n# pca.fit(X)\n# Y = data.iloc[:,13].values\n# X = data.iloc[:,0:13].values\n# reduced_data_train = pca.transform(X)\n# #inverse_data = pca.inverse_transform(reduced_data)\n# plt.scatter(reduced_data_train[:, 0], reduced_data_train[:, 1], label='reduced')\n# plt.xlabel('First Principal Component')\n# plt.ylabel('Second Principal Component')\n# plt.show()\n\n\n\npca2 = PCA(n_components=2)\npca2.fit(X)\nX1=pca2.fit_transform(X)\n\n\nwith plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(12, 8))\n    for lab, col in zip((0, 1),\n                        ('blue', 'red')):\n        plt.scatter(X1[Y==lab, 0],\n                    X1[Y==lab, 1],\n                    label=lab,\n                    c=col)\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.legend(loc='lower center')\n    plt.tight_layout()\n    plt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aab1e752ff851da1dd0713e08c5a9f69e3cd501c"
      },
      "cell_type": "code",
      "source": "def pca_results(good_data, pca):\n\t'''\n\tCreate a DataFrame of the PCA results\n\tIncludes dimension feature weights and explained variance\n\tVisualizes the PCA results\n\t'''\n\n\t# Dimension indexing\n\tdimensions = dimensions = ['Dimension {}'.format(i) for i in range(1,len(pca.components_)+1)]\n\n\t# PCA components\n\tcomponents = pd.DataFrame(np.round(pca.components_, 4), columns = list(good_data.keys()))\n\tcomponents.index = dimensions\n\n\t# PCA explained variance\n\tratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\n\tvariance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance'])\n\tvariance_ratios.index = dimensions\n\n\t# Create a bar plot visualization\n\tfig, ax = plt.subplots(figsize = (14,8))\n\n\t# Plot the feature weights as a function of the components\n\tcomponents.plot(ax = ax, kind = 'bar');\n\tax.set_ylabel(\"Feature Weights\")\n\tax.set_xticklabels(dimensions, rotation=0)\n\n\n\t# Display the explained variance ratios\n\tfor i, ev in enumerate(pca.explained_variance_ratio_):\n\t\tax.text(i-0.40, ax.get_ylim()[1] + 0.05, \"                       Explained Variance\\n                               %.4f\"%(ev))\n\n\t# Return a concatenated DataFrame\n\treturn pd.concat([variance_ratios, components], axis = 1)\n\n\npca_results = pca_results(dataX, pca2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c2113b9f0a88d41367fd236e8a4f419341e886b"
      },
      "cell_type": "code",
      "source": "data",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}